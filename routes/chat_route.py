# routes/chat_route.py

from dotenv import load_dotenv
import os
from flask import Blueprint, request, jsonify
from db import get_connection
from openai import OpenAI
import datetime

# ğŸ”‘ .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

chat_bp = Blueprint('chat', __name__)

# GPTì—ê²Œ ì§ˆë¬¸ ì˜ë„(intent) ì¶”ì¶œ
def get_intent(message):
    prompt = f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì˜ë„ë¥¼ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ íŒë‹¨í•´ì„œ í•´ë‹¹ ì´ë¦„ë§Œ ì¶œë ¥í•´.
    - CURRENT_STATUS: ì§€ê¸ˆ ìƒíƒœ ì–´ë•Œ?
    - LAST_WATERED: ìµœê·¼ì— ë¬¼ ì¤€ ì‹œê°„
    - EMOTIONAL_CHECK: ìš”ì¦˜ ê¸°ë¶„ ì–´ë•Œ?

    ì§ˆë¬¸: "{message}"
    ë‹µë³€ì€ ë°˜ë“œì‹œ ì˜ë„ í‚¤ì›Œë“œë§Œ ì¶œë ¥í•´.
    """

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

# ì±—ë´‡ API ë¼ìš°íŠ¸
@chat_bp.route('/api/chat', methods=['POST'])
def chat():
    user_msg = request.json.get('message')
    intent = get_intent(user_msg)

    conn = get_connection()
    cursor = conn.cursor(dictionary=True)

    if intent == 'CURRENT_STATUS':
        cursor.execute("SELECT * FROM sensor_log ORDER BY timestamp DESC LIMIT 1")
        row = cursor.fetchone()
        data = f"ì˜¨ë„ {row['temperature']}Â°C, ìŠµë„ {row['humidity']}%, í† ì–‘ ìƒíƒœëŠ” {'ê±´ì¡°í•¨' if row['soil_dry'] else 'ì´‰ì´‰í•¨'}ì…ë‹ˆë‹¤."
        prompt = f"""
        ì§ˆë¬¸: {user_msg}
        ì‹ë¬´ë¦¬ì˜ í˜„ì¬ ìƒíƒœëŠ” ë‹¤ìŒê³¼ ê°™ì•„ìš”:
        {data}
        ì‹ë¬´ë¦¬ë¼ëŠ” ì´ë¦„ì˜ ê·€ì—¬ìš´ ì‹ë¬¼ì´ ê°ì„±ì ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì•Œë ¤ì£¼ëŠ” ë§íˆ¬ë¡œ í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•´ì¤˜.
        ì¤„ë°”ê¿ˆê³¼ ì´ëª¨í‹°ì½˜ë„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•´ì¤˜.
        """

    elif intent == 'LAST_WATERED':
        cursor.execute("SELECT * FROM watering_log ORDER BY timestamp DESC LIMIT 1")
        row = cursor.fetchone()
        time_str = row['timestamp'].strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')
        method = "ìˆ˜ë™ìœ¼ë¡œ" if row['method'] == 'manual' else "ìë™ìœ¼ë¡œ"
        prompt = f"""
        ì§ˆë¬¸: {user_msg}
        ê°€ì¥ ìµœê·¼ ë¬¼ ì¤€ ê¸°ë¡ì€ ë‹¤ìŒê³¼ ê°™ì•„ìš”:
        - ì‹œê°„: {time_str}
        - ë°©ì‹: {method}
        ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ë¬´ë¦¬ê°€ ë§í•˜ë“¯ì´ ëŒ€ë‹µí•´ì¤˜. ê·€ì—½ê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ.
        """

    elif intent == 'EMOTIONAL_CHECK':
        cursor.execute("SELECT * FROM sensor_log ORDER BY timestamp DESC LIMIT 1")
        row = cursor.fetchone()
        mood = "ë¬¼ì„ ì•ˆ ì¤˜ì„œ ì‚´ì§ ëª©ì´ ë§ë¼ìš”... ğŸ¥º" if row['soil_dry'] else "í† ì–‘ì´ ì´‰ì´‰í•´ì„œ ê¸°ë¶„ì´ ì¢‹ì•„ìš”! ğŸŒ¸"
        prompt = f"""
        ì§ˆë¬¸: {user_msg}
        ì‹ë¬´ë¦¬ì˜ ìƒíƒœ ë¶„ì„ ê²°ê³¼:
        {mood}
        ì´ ëŠë‚Œì„ ë°”íƒ•ìœ¼ë¡œ ì‹ë¬´ë¦¬ê°€ ê°ì„±ì ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜. ë„ˆë¬´ ê¸¸ì§„ ì•Šê²Œ, ì´ëª¨í‹°ì½˜ í¬í•¨.
        """

    else:
        prompt = f"""
        ì§ˆë¬¸: {user_msg}
        ì‹ë¬´ë¦¬ë¼ëŠ” ì‹ë¬¼ ìºë¦­í„°ê°€ ì˜ˆì˜ ë°”ë¥´ê²Œ ì‘ë‹µí•´ì¤˜. ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ.
        """

    cursor.close()
    conn.close()

    # GPT ì‘ë‹µ ìƒì„± (ìµœì‹  ë°©ì‹)
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}]
    )
    reply = response.choices[0].message.content
    return jsonify({"reply": reply})
