# routes/chatbot/chat_route.py

from flask import Blueprint, request, jsonify
from db import get_connection
from openai import OpenAI
from dotenv import load_dotenv
from .intent import get_intent
from .response_prompt import build_prompt
from .log import maybe_save_mood_log
import os

load_dotenv()

# print("ğŸ” OPENAI_API_KEY =", os.getenv("OPENAI_API_KEY"))  // ì•„ë‹ˆ ì™œ ë˜ ì•ˆë¼ ë‹¤ì‹œ ë°œê¸‰í•´ë¼

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

chat_bp = Blueprint('chat', __name__)

@chat_bp.route('/api/chat', methods=['POST'])
def chat():
    user_msg = request.json.get('message')
    intent = get_intent(user_msg)

     # âœ… ì¶”ì²œ ì§ˆë¬¸ì¼ ê²½ìš° ì‹¤ì œ intentë¡œ ë§¤í•‘
    if intent == "RECOMMENDED_QUESTION":
        if "ìƒíƒœ" in user_msg:
            intent = "CURRENT_STATUS"
        elif "ê¸°ë¶„" in user_msg:
            intent = "EMOTIONAL_CHECK"
        elif "ë¬¼" in user_msg or "ì–¸ì œ" in user_msg:
            intent = "LAST_WATERED"
    
    conn = get_connection()
    cursor = conn.cursor(dictionary=True)

    prompt, log_data = build_prompt(intent, user_msg, cursor)
    maybe_save_mood_log(log_data)  # log_dataê°€ Noneì´ë©´ ì €ì¥ ì•ˆ í•¨

    cursor.close()
    conn.close()

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    reply = response.choices[0].message.content
    return jsonify({ "reply": reply, "face": log_data["face"]   })

# âœ… ê³µìš© GPT ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def get_gpt_reply(prompt: str) -> str:
    """
    GPT í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ í…ìŠ¤íŠ¸ ìƒì„±
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content